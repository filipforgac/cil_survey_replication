2025-01-11 02:00:16,750 [trainer.py] => Time Str >>> 0111-02-00-16-681
2025-01-11 02:00:16,956 [trainer.py] => memory_per_class: 20
2025-01-11 02:00:16,956 [trainer.py] => fixed_memory: False
2025-01-11 02:00:16,956 [trainer.py] => shuffle: True
2025-01-11 02:00:16,956 [trainer.py] => model_name: memo
2025-01-11 02:00:16,956 [trainer.py] => seed: 1993
2025-01-11 02:00:16,956 [trainer.py] => dataset: cifar100
2025-01-11 02:00:16,956 [trainer.py] => memory_size: 4771
2025-01-11 02:00:16,956 [trainer.py] => init_cls: 5
2025-01-11 02:00:16,956 [trainer.py] => increment: 5
2025-01-11 02:00:16,956 [trainer.py] => convnet_type: memo_resnet32
2025-01-11 02:00:16,956 [trainer.py] => prefix: fair
2025-01-11 02:00:16,956 [trainer.py] => device: [device(type='cuda', index=3)]
2025-01-11 02:00:16,956 [trainer.py] => debug: False
2025-01-11 02:00:16,956 [trainer.py] => skip: False
2025-01-11 02:00:16,957 [trainer.py] => train_base: True
2025-01-11 02:00:16,957 [trainer.py] => train_adaptive: False
2025-01-11 02:00:16,957 [trainer.py] => scheduler: cosine
2025-01-11 02:00:16,957 [trainer.py] => init_epoch: 200
2025-01-11 02:00:16,957 [trainer.py] => t_max: 170
2025-01-11 02:00:16,957 [trainer.py] => init_lr: 0.1
2025-01-11 02:00:16,957 [trainer.py] => init_milestones: [60, 120, 170]
2025-01-11 02:00:16,957 [trainer.py] => init_lr_decay: 0.1
2025-01-11 02:00:16,957 [trainer.py] => init_weight_decay: 0.0005
2025-01-11 02:00:16,957 [trainer.py] => epochs: 170
2025-01-11 02:00:16,957 [trainer.py] => lrate: 0.1
2025-01-11 02:00:16,957 [trainer.py] => milestones: [80, 120, 150]
2025-01-11 02:00:16,957 [trainer.py] => lrate_decay: 0.1
2025-01-11 02:00:16,957 [trainer.py] => batch_size: 128
2025-01-11 02:00:16,957 [trainer.py] => weight_decay: 0.0002
2025-01-11 02:00:16,957 [trainer.py] => alpha_aux: 1.0
2025-01-11 02:00:16,958 [trainer.py] => config: ./exps/memo.json
2025-01-11 02:00:16,958 [trainer.py] => time_str: 0111-02-00-16-681
2025-01-11 02:00:16,958 [trainer.py] => exp_name: 0111-02-00-16-681_cifar100_memo_resnet32_1993_B0_Inc5
2025-01-11 02:00:16,958 [trainer.py] => logfilename: logs/fair/cifar100/memo/0111-02-00-16-681_cifar100_memo_resnet32_1993_B0_Inc5
2025-01-11 02:00:16,958 [trainer.py] => csv_name: cifar100_1993_memo_resnet32_B0_Inc5
2025-01-11 02:00:22,808 [data_manager.py] => [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
2025-01-11 02:00:23,269 [memo.py] => >>> train generalized blocks:True train_adaptive:False
2025-01-11 02:00:23,269 [trainer.py] => Start time:1736557223.2697098
2025-01-11 02:00:23,269 [trainer.py] => All params: 112016
2025-01-11 02:00:23,270 [trainer.py] => Trainable params: 112016
2025-01-11 02:00:23,282 [inc_net.py] => SpecializedResNet_cifar(
  (final_stage): Sequential(
    (0): ResNetBasicblock(
      (conv_a): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): DownsampleA(
        (avg): AvgPool2d(kernel_size=1, stride=2, padding=0)
      )
    )
    (1): ResNetBasicblock(
      (conv_a): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ResNetBasicblock(
      (conv_a): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): ResNetBasicblock(
      (conv_a): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): ResNetBasicblock(
      (conv_a): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)
)
2025-01-11 02:00:23,283 [memo.py] => Learning on 0-5
2025-01-11 02:00:23,283 [memo.py] => All params: 464219
2025-01-11 02:00:23,283 [memo.py] => Trainable params: 464219
2025-01-11 02:00:37,418 [memo.py] => Task 0, Epoch 1/200 => Loss 3.392, Train_accy 20.48, Test_accy 23.20
2025-01-11 02:00:39,521 [memo.py] => Task 0, Epoch 2/200 => Loss 1.609, Train_accy 23.00
2025-01-11 02:00:41,555 [memo.py] => Task 0, Epoch 3/200 => Loss 1.601, Train_accy 23.20
2025-01-11 02:00:43,912 [memo.py] => Task 0, Epoch 4/200 => Loss 1.598, Train_accy 23.04
2025-01-11 02:00:46,058 [memo.py] => Task 0, Epoch 5/200 => Loss 1.594, Train_accy 21.76
2025-01-11 02:00:50,052 [memo.py] => Task 0, Epoch 6/200 => Loss 1.593, Train_accy 25.48, Test_accy 19.60
2025-01-11 02:00:52,098 [memo.py] => Task 0, Epoch 7/200 => Loss 1.585, Train_accy 24.60
2025-01-11 02:00:54,060 [memo.py] => Task 0, Epoch 8/200 => Loss 1.578, Train_accy 26.32
2025-01-11 02:00:56,386 [memo.py] => Task 0, Epoch 9/200 => Loss 1.570, Train_accy 26.08
2025-01-11 02:00:58,510 [memo.py] => Task 0, Epoch 10/200 => Loss 1.536, Train_accy 31.80
2025-01-11 02:01:02,636 [memo.py] => Task 0, Epoch 11/200 => Loss 1.468, Train_accy 36.68, Test_accy 43.60
2025-01-11 02:01:04,721 [memo.py] => Task 0, Epoch 12/200 => Loss 1.391, Train_accy 43.68
2025-01-11 02:01:06,555 [memo.py] => Task 0, Epoch 13/200 => Loss 1.240, Train_accy 52.20
2025-01-11 02:01:08,958 [memo.py] => Task 0, Epoch 14/200 => Loss 1.101, Train_accy 57.04
2025-01-11 02:01:11,070 [memo.py] => Task 0, Epoch 15/200 => Loss 1.005, Train_accy 60.56
2025-01-11 02:01:14,779 [memo.py] => Task 0, Epoch 16/200 => Loss 0.914, Train_accy 64.72, Test_accy 63.00
2025-01-11 02:01:16,890 [memo.py] => Task 0, Epoch 17/200 => Loss 0.856, Train_accy 66.76
2025-01-11 02:01:19,145 [memo.py] => Task 0, Epoch 18/200 => Loss 0.763, Train_accy 69.40
2025-01-11 02:01:21,317 [memo.py] => Task 0, Epoch 19/200 => Loss 0.726, Train_accy 70.36
2025-01-11 02:01:23,381 [memo.py] => Task 0, Epoch 20/200 => Loss 0.678, Train_accy 73.04
2025-01-11 02:01:27,171 [memo.py] => Task 0, Epoch 21/200 => Loss 0.601, Train_accy 75.04, Test_accy 75.60
2025-01-11 02:01:29,420 [memo.py] => Task 0, Epoch 22/200 => Loss 0.609, Train_accy 75.68
2025-01-11 02:01:31,691 [memo.py] => Task 0, Epoch 23/200 => Loss 0.548, Train_accy 77.80
2025-01-11 02:01:33,943 [memo.py] => Task 0, Epoch 24/200 => Loss 0.565, Train_accy 77.92
2025-01-11 02:01:36,282 [memo.py] => Task 0, Epoch 25/200 => Loss 0.503, Train_accy 80.88
2025-01-11 02:01:40,238 [memo.py] => Task 0, Epoch 26/200 => Loss 0.483, Train_accy 80.92, Test_accy 77.80
2025-01-11 02:01:42,412 [memo.py] => Task 0, Epoch 27/200 => Loss 0.450, Train_accy 83.20
2025-01-11 02:01:44,766 [memo.py] => Task 0, Epoch 28/200 => Loss 0.429, Train_accy 83.64
2025-01-11 02:01:47,293 [memo.py] => Task 0, Epoch 29/200 => Loss 0.415, Train_accy 83.84
2025-01-11 02:01:49,494 [memo.py] => Task 0, Epoch 30/200 => Loss 0.371, Train_accy 86.68
2025-01-11 02:01:55,235 [memo.py] => Task 0, Epoch 31/200 => Loss 0.393, Train_accy 85.12, Test_accy 71.20
2025-01-11 02:01:57,355 [memo.py] => Task 0, Epoch 32/200 => Loss 0.381, Train_accy 85.84
2025-01-11 02:01:59,649 [memo.py] => Task 0, Epoch 33/200 => Loss 0.364, Train_accy 87.16
2025-01-11 02:02:01,830 [memo.py] => Task 0, Epoch 34/200 => Loss 0.313, Train_accy 88.20
2025-01-11 02:02:04,056 [memo.py] => Task 0, Epoch 35/200 => Loss 0.289, Train_accy 89.76
2025-01-11 02:02:07,785 [memo.py] => Task 0, Epoch 36/200 => Loss 0.279, Train_accy 90.20, Test_accy 88.00
2025-01-11 02:02:10,072 [memo.py] => Task 0, Epoch 37/200 => Loss 0.292, Train_accy 89.32
2025-01-11 02:02:12,316 [memo.py] => Task 0, Epoch 38/200 => Loss 0.291, Train_accy 89.04
2025-01-11 02:02:14,331 [memo.py] => Task 0, Epoch 39/200 => Loss 0.258, Train_accy 90.48
2025-01-11 02:02:16,552 [memo.py] => Task 0, Epoch 40/200 => Loss 0.259, Train_accy 90.88
2025-01-11 02:02:20,265 [memo.py] => Task 0, Epoch 41/200 => Loss 0.244, Train_accy 91.64, Test_accy 87.00
2025-01-11 02:02:22,549 [memo.py] => Task 0, Epoch 42/200 => Loss 0.223, Train_accy 91.88
2025-01-11 02:02:24,629 [memo.py] => Task 0, Epoch 43/200 => Loss 0.222, Train_accy 91.76
2025-01-11 02:02:26,934 [memo.py] => Task 0, Epoch 44/200 => Loss 0.193, Train_accy 92.88
2025-01-11 02:02:29,097 [memo.py] => Task 0, Epoch 45/200 => Loss 0.171, Train_accy 93.92
2025-01-11 02:02:33,082 [memo.py] => Task 0, Epoch 46/200 => Loss 0.182, Train_accy 93.24, Test_accy 90.80
2025-01-11 02:02:35,255 [memo.py] => Task 0, Epoch 47/200 => Loss 0.188, Train_accy 93.24
2025-01-11 02:02:37,234 [memo.py] => Task 0, Epoch 48/200 => Loss 0.157, Train_accy 94.36
2025-01-11 02:02:39,526 [memo.py] => Task 0, Epoch 49/200 => Loss 0.170, Train_accy 93.88
2025-01-11 02:02:41,773 [memo.py] => Task 0, Epoch 50/200 => Loss 0.185, Train_accy 93.44
2025-01-11 02:02:45,650 [memo.py] => Task 0, Epoch 51/200 => Loss 0.179, Train_accy 93.72, Test_accy 90.40
2025-01-11 02:02:47,698 [memo.py] => Task 0, Epoch 52/200 => Loss 0.146, Train_accy 94.80
2025-01-11 02:02:50,031 [memo.py] => Task 0, Epoch 53/200 => Loss 0.154, Train_accy 94.64
2025-01-11 02:02:52,216 [memo.py] => Task 0, Epoch 54/200 => Loss 0.146, Train_accy 94.84
2025-01-11 02:02:54,409 [memo.py] => Task 0, Epoch 55/200 => Loss 0.172, Train_accy 93.72
2025-01-11 02:02:58,152 [memo.py] => Task 0, Epoch 56/200 => Loss 0.162, Train_accy 94.04, Test_accy 88.60
2025-01-11 02:03:00,362 [memo.py] => Task 0, Epoch 57/200 => Loss 0.101, Train_accy 96.88
2025-01-11 02:03:02,571 [memo.py] => Task 0, Epoch 58/200 => Loss 0.093, Train_accy 96.80
2025-01-11 02:03:05,090 [memo.py] => Task 0, Epoch 59/200 => Loss 0.100, Train_accy 96.60
2025-01-11 02:03:07,435 [memo.py] => Task 0, Epoch 60/200 => Loss 0.097, Train_accy 96.24
2025-01-11 02:03:11,257 [memo.py] => Task 0, Epoch 61/200 => Loss 0.085, Train_accy 96.92, Test_accy 87.00
2025-01-11 02:03:13,442 [memo.py] => Task 0, Epoch 62/200 => Loss 0.109, Train_accy 95.80
2025-01-11 02:03:15,948 [memo.py] => Task 0, Epoch 63/200 => Loss 0.084, Train_accy 97.12
2025-01-11 02:03:19,236 [memo.py] => Task 0, Epoch 64/200 => Loss 0.086, Train_accy 97.12
2025-01-11 02:03:21,424 [memo.py] => Task 0, Epoch 65/200 => Loss 0.090, Train_accy 96.40
2025-01-11 02:03:25,299 [memo.py] => Task 0, Epoch 66/200 => Loss 0.082, Train_accy 97.24, Test_accy 89.00
2025-01-11 02:03:27,640 [memo.py] => Task 0, Epoch 67/200 => Loss 0.087, Train_accy 96.84
2025-01-11 02:03:29,656 [memo.py] => Task 0, Epoch 68/200 => Loss 0.102, Train_accy 96.84
2025-01-11 02:03:31,991 [memo.py] => Task 0, Epoch 69/200 => Loss 0.104, Train_accy 96.16
2025-01-11 02:03:34,130 [memo.py] => Task 0, Epoch 70/200 => Loss 0.096, Train_accy 96.96
2025-01-11 02:03:37,948 [memo.py] => Task 0, Epoch 71/200 => Loss 0.084, Train_accy 96.92, Test_accy 92.20
2025-01-11 02:03:40,155 [memo.py] => Task 0, Epoch 72/200 => Loss 0.076, Train_accy 97.16
2025-01-11 02:03:42,418 [memo.py] => Task 0, Epoch 73/200 => Loss 0.073, Train_accy 97.48
2025-01-11 02:03:44,372 [memo.py] => Task 0, Epoch 74/200 => Loss 0.043, Train_accy 98.84
2025-01-11 02:03:46,471 [memo.py] => Task 0, Epoch 75/200 => Loss 0.057, Train_accy 97.80
2025-01-11 02:03:50,510 [memo.py] => Task 0, Epoch 76/200 => Loss 0.059, Train_accy 98.08, Test_accy 94.40
2025-01-11 02:03:52,723 [memo.py] => Task 0, Epoch 77/200 => Loss 0.040, Train_accy 98.72
2025-01-11 02:03:54,996 [memo.py] => Task 0, Epoch 78/200 => Loss 0.038, Train_accy 98.68
2025-01-11 02:03:57,240 [memo.py] => Task 0, Epoch 79/200 => Loss 0.049, Train_accy 98.20
2025-01-11 02:03:59,684 [memo.py] => Task 0, Epoch 80/200 => Loss 0.043, Train_accy 98.80
2025-01-11 02:04:03,913 [memo.py] => Task 0, Epoch 81/200 => Loss 0.051, Train_accy 98.64, Test_accy 92.80
2025-01-11 02:04:05,966 [memo.py] => Task 0, Epoch 82/200 => Loss 0.055, Train_accy 98.04
2025-01-11 02:04:08,317 [memo.py] => Task 0, Epoch 83/200 => Loss 0.077, Train_accy 97.16
2025-01-11 02:04:10,485 [memo.py] => Task 0, Epoch 84/200 => Loss 0.099, Train_accy 96.60
2025-01-11 02:04:12,524 [memo.py] => Task 0, Epoch 85/200 => Loss 0.063, Train_accy 97.64
2025-01-11 02:04:16,379 [memo.py] => Task 0, Epoch 86/200 => Loss 0.047, Train_accy 98.56, Test_accy 94.60
2025-01-11 02:04:18,514 [memo.py] => Task 0, Epoch 87/200 => Loss 0.043, Train_accy 98.40
2025-01-11 02:04:20,698 [memo.py] => Task 0, Epoch 88/200 => Loss 0.051, Train_accy 98.48
2025-01-11 02:04:23,050 [memo.py] => Task 0, Epoch 89/200 => Loss 0.042, Train_accy 98.76
2025-01-11 02:04:25,160 [memo.py] => Task 0, Epoch 90/200 => Loss 0.037, Train_accy 98.84
2025-01-11 02:04:29,154 [memo.py] => Task 0, Epoch 91/200 => Loss 0.029, Train_accy 99.12, Test_accy 93.20
2025-01-11 02:04:31,372 [memo.py] => Task 0, Epoch 92/200 => Loss 0.037, Train_accy 98.80
2025-01-11 02:04:33,443 [memo.py] => Task 0, Epoch 93/200 => Loss 0.030, Train_accy 99.12
2025-01-11 02:04:35,709 [memo.py] => Task 0, Epoch 94/200 => Loss 0.043, Train_accy 98.52
2025-01-11 02:04:38,037 [memo.py] => Task 0, Epoch 95/200 => Loss 0.039, Train_accy 98.64
2025-01-11 02:04:41,718 [memo.py] => Task 0, Epoch 96/200 => Loss 0.037, Train_accy 98.72, Test_accy 93.20
2025-01-11 02:04:43,864 [memo.py] => Task 0, Epoch 97/200 => Loss 0.036, Train_accy 98.88
2025-01-11 02:04:46,065 [memo.py] => Task 0, Epoch 98/200 => Loss 0.033, Train_accy 99.12
2025-01-11 02:04:48,445 [memo.py] => Task 0, Epoch 99/200 => Loss 0.026, Train_accy 99.28
2025-01-11 02:04:50,673 [memo.py] => Task 0, Epoch 100/200 => Loss 0.028, Train_accy 99.08
2025-01-11 02:04:54,793 [memo.py] => Task 0, Epoch 101/200 => Loss 0.015, Train_accy 99.56, Test_accy 93.40
2025-01-11 02:04:57,119 [memo.py] => Task 0, Epoch 102/200 => Loss 0.015, Train_accy 99.56
2025-01-11 02:04:59,375 [memo.py] => Task 0, Epoch 103/200 => Loss 0.012, Train_accy 99.68
2025-01-11 02:05:01,644 [memo.py] => Task 0, Epoch 104/200 => Loss 0.010, Train_accy 99.76
2025-01-11 02:05:03,612 [memo.py] => Task 0, Epoch 105/200 => Loss 0.014, Train_accy 99.68
2025-01-11 02:05:07,434 [memo.py] => Task 0, Epoch 106/200 => Loss 0.014, Train_accy 99.64, Test_accy 93.80
2025-01-11 02:05:09,452 [memo.py] => Task 0, Epoch 107/200 => Loss 0.019, Train_accy 99.40
2025-01-11 02:05:11,594 [memo.py] => Task 0, Epoch 108/200 => Loss 0.024, Train_accy 99.28
2025-01-11 02:05:13,867 [memo.py] => Task 0, Epoch 109/200 => Loss 0.018, Train_accy 99.48
2025-01-11 02:05:16,161 [memo.py] => Task 0, Epoch 110/200 => Loss 0.014, Train_accy 99.68
2025-01-11 02:05:20,153 [memo.py] => Task 0, Epoch 111/200 => Loss 0.022, Train_accy 99.32, Test_accy 94.40
2025-01-11 02:05:22,183 [memo.py] => Task 0, Epoch 112/200 => Loss 0.016, Train_accy 99.40
2025-01-11 02:05:24,467 [memo.py] => Task 0, Epoch 113/200 => Loss 0.022, Train_accy 99.32
2025-01-11 02:05:26,702 [memo.py] => Task 0, Epoch 114/200 => Loss 0.020, Train_accy 99.28
2025-01-11 02:05:28,948 [memo.py] => Task 0, Epoch 115/200 => Loss 0.026, Train_accy 99.12
2025-01-11 02:05:32,647 [memo.py] => Task 0, Epoch 116/200 => Loss 0.021, Train_accy 99.36, Test_accy 94.60
2025-01-11 02:05:34,805 [memo.py] => Task 0, Epoch 117/200 => Loss 0.015, Train_accy 99.56
2025-01-11 02:05:36,906 [memo.py] => Task 0, Epoch 118/200 => Loss 0.009, Train_accy 99.72
2025-01-11 02:05:39,129 [memo.py] => Task 0, Epoch 119/200 => Loss 0.009, Train_accy 99.84
2025-01-11 02:05:41,239 [memo.py] => Task 0, Epoch 120/200 => Loss 0.009, Train_accy 99.84
2025-01-11 02:05:45,011 [memo.py] => Task 0, Epoch 121/200 => Loss 0.008, Train_accy 99.88, Test_accy 95.00
2025-01-11 02:05:47,179 [memo.py] => Task 0, Epoch 122/200 => Loss 0.010, Train_accy 99.72
2025-01-11 02:05:49,626 [memo.py] => Task 0, Epoch 123/200 => Loss 0.007, Train_accy 99.88
2025-01-11 02:05:51,666 [memo.py] => Task 0, Epoch 124/200 => Loss 0.005, Train_accy 99.96
2025-01-11 02:05:53,963 [memo.py] => Task 0, Epoch 125/200 => Loss 0.004, Train_accy 99.92
2025-01-11 02:05:57,766 [memo.py] => Task 0, Epoch 126/200 => Loss 0.009, Train_accy 99.64, Test_accy 94.80
2025-01-11 02:06:00,037 [memo.py] => Task 0, Epoch 127/200 => Loss 0.009, Train_accy 99.68
2025-01-11 02:06:02,181 [memo.py] => Task 0, Epoch 128/200 => Loss 0.006, Train_accy 99.84
2025-01-11 02:06:04,280 [memo.py] => Task 0, Epoch 129/200 => Loss 0.008, Train_accy 99.80
2025-01-11 02:06:06,416 [memo.py] => Task 0, Epoch 130/200 => Loss 0.006, Train_accy 99.92
2025-01-11 02:06:10,444 [memo.py] => Task 0, Epoch 131/200 => Loss 0.004, Train_accy 99.92, Test_accy 95.40
2025-01-11 02:06:12,556 [memo.py] => Task 0, Epoch 132/200 => Loss 0.004, Train_accy 99.88
2025-01-11 02:06:14,892 [memo.py] => Task 0, Epoch 133/200 => Loss 0.003, Train_accy 99.96
2025-01-11 02:06:17,216 [memo.py] => Task 0, Epoch 134/200 => Loss 0.004, Train_accy 99.92
2025-01-11 02:06:19,500 [memo.py] => Task 0, Epoch 135/200 => Loss 0.005, Train_accy 99.92
2025-01-11 02:06:23,174 [memo.py] => Task 0, Epoch 136/200 => Loss 0.006, Train_accy 99.80, Test_accy 94.80
2025-01-11 02:06:25,385 [memo.py] => Task 0, Epoch 137/200 => Loss 0.004, Train_accy 99.88
2025-01-11 02:06:27,848 [memo.py] => Task 0, Epoch 138/200 => Loss 0.006, Train_accy 99.84
2025-01-11 02:06:30,040 [memo.py] => Task 0, Epoch 139/200 => Loss 0.006, Train_accy 99.80
2025-01-11 02:06:32,291 [memo.py] => Task 0, Epoch 140/200 => Loss 0.004, Train_accy 99.96
2025-01-11 02:06:36,217 [memo.py] => Task 0, Epoch 141/200 => Loss 0.004, Train_accy 99.92, Test_accy 95.20
2025-01-11 02:06:38,456 [memo.py] => Task 0, Epoch 142/200 => Loss 0.002, Train_accy 100.00
2025-01-11 02:06:40,569 [memo.py] => Task 0, Epoch 143/200 => Loss 0.002, Train_accy 100.00
2025-01-11 02:06:42,734 [memo.py] => Task 0, Epoch 144/200 => Loss 0.002, Train_accy 100.00
2025-01-11 02:06:44,730 [memo.py] => Task 0, Epoch 145/200 => Loss 0.003, Train_accy 99.96
2025-01-11 02:06:48,563 [memo.py] => Task 0, Epoch 146/200 => Loss 0.005, Train_accy 99.88, Test_accy 93.80
2025-01-11 02:06:50,790 [memo.py] => Task 0, Epoch 147/200 => Loss 0.004, Train_accy 99.96
2025-01-11 02:06:53,097 [memo.py] => Task 0, Epoch 148/200 => Loss 0.002, Train_accy 100.00
2025-01-11 02:06:55,498 [memo.py] => Task 0, Epoch 149/200 => Loss 0.004, Train_accy 99.96
2025-01-11 02:06:57,787 [memo.py] => Task 0, Epoch 150/200 => Loss 0.006, Train_accy 99.84
2025-01-11 02:07:01,328 [memo.py] => Task 0, Epoch 151/200 => Loss 0.003, Train_accy 99.96, Test_accy 96.60
2025-01-11 02:07:03,561 [memo.py] => Task 0, Epoch 152/200 => Loss 0.002, Train_accy 100.00
2025-01-11 02:07:05,538 [memo.py] => Task 0, Epoch 153/200 => Loss 0.002, Train_accy 100.00
2025-01-11 02:07:07,871 [memo.py] => Task 0, Epoch 154/200 => Loss 0.004, Train_accy 99.92
2025-01-11 02:07:10,061 [memo.py] => Task 0, Epoch 155/200 => Loss 0.003, Train_accy 99.96
2025-01-11 02:07:14,000 [memo.py] => Task 0, Epoch 156/200 => Loss 0.003, Train_accy 99.92, Test_accy 95.80
2025-01-11 02:07:16,373 [memo.py] => Task 0, Epoch 157/200 => Loss 0.002, Train_accy 100.00
2025-01-11 02:07:18,653 [memo.py] => Task 0, Epoch 158/200 => Loss 0.002, Train_accy 100.00
2025-01-11 02:07:20,789 [memo.py] => Task 0, Epoch 159/200 => Loss 0.002, Train_accy 100.00
2025-01-11 02:07:23,182 [memo.py] => Task 0, Epoch 160/200 => Loss 0.002, Train_accy 100.00
2025-01-11 02:07:29,045 [memo.py] => Task 0, Epoch 161/200 => Loss 0.002, Train_accy 99.96, Test_accy 96.20
2025-01-11 02:07:31,259 [memo.py] => Task 0, Epoch 162/200 => Loss 0.001, Train_accy 100.00
2025-01-11 02:07:33,478 [memo.py] => Task 0, Epoch 163/200 => Loss 0.002, Train_accy 100.00
2025-01-11 02:07:35,727 [memo.py] => Task 0, Epoch 164/200 => Loss 0.002, Train_accy 100.00
2025-01-11 02:07:37,865 [memo.py] => Task 0, Epoch 165/200 => Loss 0.003, Train_accy 99.92
2025-01-11 02:07:41,617 [memo.py] => Task 0, Epoch 166/200 => Loss 0.002, Train_accy 100.00, Test_accy 95.60
2025-01-11 02:07:43,742 [memo.py] => Task 0, Epoch 167/200 => Loss 0.001, Train_accy 100.00
2025-01-11 02:07:45,950 [memo.py] => Task 0, Epoch 168/200 => Loss 0.001, Train_accy 100.00
2025-01-11 02:07:48,130 [memo.py] => Task 0, Epoch 169/200 => Loss 0.003, Train_accy 99.96
2025-01-11 02:07:50,303 [memo.py] => Task 0, Epoch 170/200 => Loss 0.003, Train_accy 99.88
2025-01-11 02:07:54,291 [memo.py] => Task 0, Epoch 171/200 => Loss 0.002, Train_accy 100.00, Test_accy 95.60
2025-01-11 02:07:56,565 [memo.py] => Task 0, Epoch 172/200 => Loss 0.002, Train_accy 100.00
2025-01-11 02:07:58,813 [memo.py] => Task 0, Epoch 173/200 => Loss 0.002, Train_accy 100.00
2025-01-11 02:08:01,055 [memo.py] => Task 0, Epoch 174/200 => Loss 0.002, Train_accy 100.00
2025-01-11 02:08:03,408 [memo.py] => Task 0, Epoch 175/200 => Loss 0.002, Train_accy 100.00
2025-01-11 02:08:08,437 [memo.py] => Task 0, Epoch 176/200 => Loss 0.002, Train_accy 100.00, Test_accy 95.60
2025-01-11 02:08:10,731 [memo.py] => Task 0, Epoch 177/200 => Loss 0.002, Train_accy 100.00
2025-01-11 02:08:12,659 [memo.py] => Task 0, Epoch 178/200 => Loss 0.002, Train_accy 100.00
2025-01-11 02:08:14,897 [memo.py] => Task 0, Epoch 179/200 => Loss 0.001, Train_accy 100.00
2025-01-11 02:08:17,174 [memo.py] => Task 0, Epoch 180/200 => Loss 0.002, Train_accy 100.00
2025-01-11 02:08:21,132 [memo.py] => Task 0, Epoch 181/200 => Loss 0.002, Train_accy 100.00, Test_accy 95.60
2025-01-11 02:08:23,056 [memo.py] => Task 0, Epoch 182/200 => Loss 0.002, Train_accy 99.92
2025-01-11 02:08:25,288 [memo.py] => Task 0, Epoch 183/200 => Loss 0.001, Train_accy 100.00
2025-01-11 02:08:27,672 [memo.py] => Task 0, Epoch 184/200 => Loss 0.002, Train_accy 99.96
2025-01-11 02:08:29,803 [memo.py] => Task 0, Epoch 185/200 => Loss 0.002, Train_accy 100.00
2025-01-11 02:08:33,768 [memo.py] => Task 0, Epoch 186/200 => Loss 0.002, Train_accy 100.00, Test_accy 95.40
2025-01-11 02:08:36,146 [memo.py] => Task 0, Epoch 187/200 => Loss 0.002, Train_accy 100.00
2025-01-11 02:08:38,429 [memo.py] => Task 0, Epoch 188/200 => Loss 0.002, Train_accy 100.00
2025-01-11 02:08:40,730 [memo.py] => Task 0, Epoch 189/200 => Loss 0.001, Train_accy 100.00
2025-01-11 02:08:43,105 [memo.py] => Task 0, Epoch 190/200 => Loss 0.002, Train_accy 99.92
2025-01-11 02:08:46,713 [memo.py] => Task 0, Epoch 191/200 => Loss 0.001, Train_accy 100.00, Test_accy 95.60
2025-01-11 02:08:48,929 [memo.py] => Task 0, Epoch 192/200 => Loss 0.002, Train_accy 100.00
2025-01-11 02:08:51,300 [memo.py] => Task 0, Epoch 193/200 => Loss 0.001, Train_accy 100.00
2025-01-11 02:08:53,356 [memo.py] => Task 0, Epoch 194/200 => Loss 0.002, Train_accy 100.00
2025-01-11 02:08:55,575 [memo.py] => Task 0, Epoch 195/200 => Loss 0.001, Train_accy 100.00
2025-01-11 02:08:59,467 [memo.py] => Task 0, Epoch 196/200 => Loss 0.001, Train_accy 100.00, Test_accy 95.80
2025-01-11 02:09:01,606 [memo.py] => Task 0, Epoch 197/200 => Loss 0.001, Train_accy 100.00
2025-01-11 02:09:03,994 [memo.py] => Task 0, Epoch 198/200 => Loss 0.002, Train_accy 100.00
2025-01-11 02:09:06,322 [memo.py] => Task 0, Epoch 199/200 => Loss 0.002, Train_accy 100.00
2025-01-11 02:09:08,450 [memo.py] => Task 0, Epoch 200/200 => Loss 0.002, Train_accy 99.96
2025-01-11 02:09:08,451 [base.py] => Reducing exemplars...(954 per classes)
2025-01-11 02:09:08,451 [base.py] => Constructing exemplars...(954 per classes)
2025-01-11 02:09:22,697 [memo.py] => Train Generalized Blocks...
2025-01-11 02:09:22,701 [memo.py] => Exemplar size: 2500
2025-01-11 02:09:22,701 [trainer.py] => CNN: {'total': np.float64(95.4), '00-09': np.float64(95.4), 'old': 0, 'new': np.float64(95.4)}
2025-01-11 02:09:22,702 [trainer.py] => NME: {'total': np.float64(95.8), '00-09': np.float64(95.8), 'old': 0, 'new': np.float64(95.8)}
2025-01-11 02:09:22,702 [trainer.py] => CNN top1 curve: [np.float64(95.4)]
2025-01-11 02:09:22,702 [trainer.py] => CNN top5 curve: [np.float64(100.0)]
2025-01-11 02:09:22,702 [trainer.py] => NME top1 curve: [np.float64(95.8)]
2025-01-11 02:09:22,702 [trainer.py] => NME top5 curve: [np.float64(100.0)]

2025-01-11 02:09:22,702 [trainer.py] => All params: 464219
2025-01-11 02:09:22,703 [trainer.py] => Trainable params: 464219
2025-01-11 02:09:22,852 [memo.py] => Learning on 5-10
2025-01-11 02:09:22,853 [memo.py] => All params: 816672
2025-01-11 02:09:22,853 [memo.py] => Trainable params: 465184
2025-01-11 02:18:32,613 [memo.py] => Task 1, Epoch 170/170 => Loss 0.026, Loss_clf 0.012, Loss_aux 0.014, Train_accy 99.70
2025-01-11 02:18:34,218 [base.py] => Reducing exemplars...(477 per classes)
2025-01-11 02:18:39,271 [base.py] => Constructing exemplars...(477 per classes)
2025-01-11 02:18:53,245 [memo.py] => Exemplar size: 4770
2025-01-11 02:18:53,245 [trainer.py] => CNN: {'total': np.float64(90.6), '00-09': np.float64(90.6), 'old': np.float64(93.4), 'new': np.float64(87.8)}
2025-01-11 02:18:53,245 [trainer.py] => NME: {'total': np.float64(90.5), '00-09': np.float64(90.5), 'old': np.float64(93.6), 'new': np.float64(87.4)}
2025-01-11 02:18:53,245 [trainer.py] => CNN top1 curve: [np.float64(95.4), np.float64(90.6)]
2025-01-11 02:18:53,245 [trainer.py] => CNN top5 curve: [np.float64(100.0), np.float64(99.3)]
2025-01-11 02:18:53,245 [trainer.py] => NME top1 curve: [np.float64(95.8), np.float64(90.5)]
2025-01-11 02:18:53,245 [trainer.py] => NME top5 curve: [np.float64(100.0), np.float64(99.4)]

2025-01-11 02:18:53,246 [trainer.py] => All params: 816672
2025-01-11 02:18:53,246 [trainer.py] => Trainable params: 465184
2025-01-11 02:18:53,263 [memo.py] => Learning on 10-15
2025-01-11 02:18:53,263 [memo.py] => All params: 1169765
2025-01-11 02:18:53,264 [memo.py] => Trainable params: 466789
2025-01-11 02:29:57,964 [memo.py] => Task 2, Epoch 170/170 => Loss 0.006, Loss_clf 0.005, Loss_aux 0.002, Train_accy 99.92
2025-01-11 02:29:57,969 [base.py] => Reducing exemplars...(318 per classes)
2025-01-11 02:30:08,781 [base.py] => Constructing exemplars...(318 per classes)
2025-01-11 02:30:23,617 [memo.py] => Exemplar size: 4770
2025-01-11 02:30:23,617 [trainer.py] => CNN: {'total': np.float64(84.07), '00-09': np.float64(87.5), '10-19': np.float64(77.2), 'old': np.float64(87.5), 'new': np.float64(77.2)}
2025-01-11 02:30:23,617 [trainer.py] => NME: {'total': np.float64(82.2), '00-09': np.float64(87.1), '10-19': np.float64(72.4), 'old': np.float64(87.1), 'new': np.float64(72.4)}
2025-01-11 02:30:23,617 [trainer.py] => CNN top1 curve: [np.float64(95.4), np.float64(90.6), np.float64(84.07)]
2025-01-11 02:30:23,617 [trainer.py] => CNN top5 curve: [np.float64(100.0), np.float64(99.3), np.float64(98.0)]
2025-01-11 02:30:23,617 [trainer.py] => NME top1 curve: [np.float64(95.8), np.float64(90.5), np.float64(82.2)]
2025-01-11 02:30:23,617 [trainer.py] => NME top5 curve: [np.float64(100.0), np.float64(99.4), np.float64(97.8)]

2025-01-11 02:30:23,618 [trainer.py] => All params: 1169765
2025-01-11 02:30:23,618 [trainer.py] => Trainable params: 466789
2025-01-11 02:30:23,630 [memo.py] => Learning on 15-20
2025-01-11 02:30:23,631 [memo.py] => All params: 1523498
2025-01-11 02:30:23,631 [memo.py] => Trainable params: 469034
2025-01-11 02:41:52,994 [memo.py] => Task 3, Epoch 170/170 => Loss 0.005, Loss_clf 0.004, Loss_aux 0.001, Train_accy 100.00
2025-01-11 02:41:52,999 [base.py] => Reducing exemplars...(238 per classes)
2025-01-11 02:42:07,284 [base.py] => Constructing exemplars...(238 per classes)
2025-01-11 02:42:20,997 [memo.py] => Exemplar size: 4760
2025-01-11 02:42:20,997 [trainer.py] => CNN: {'total': np.float64(79.7), '00-09': np.float64(84.4), '10-19': np.float64(75.0), 'old': np.float64(81.27), 'new': np.float64(75.0)}
2025-01-11 02:42:20,997 [trainer.py] => NME: {'total': np.float64(78.7), '00-09': np.float64(85.1), '10-19': np.float64(72.3), 'old': np.float64(81.53), 'new': np.float64(70.2)}
2025-01-11 02:42:20,997 [trainer.py] => CNN top1 curve: [np.float64(95.4), np.float64(90.6), np.float64(84.07), np.float64(79.7)]
2025-01-11 02:42:20,997 [trainer.py] => CNN top5 curve: [np.float64(100.0), np.float64(99.3), np.float64(98.0), np.float64(96.1)]
2025-01-11 02:42:20,997 [trainer.py] => NME top1 curve: [np.float64(95.8), np.float64(90.5), np.float64(82.2), np.float64(78.7)]
2025-01-11 02:42:20,997 [trainer.py] => NME top5 curve: [np.float64(100.0), np.float64(99.4), np.float64(97.8), np.float64(95.95)]

2025-01-11 02:42:20,997 [trainer.py] => All params: 1523498
2025-01-11 02:42:20,998 [trainer.py] => Trainable params: 469034
2025-01-11 02:42:21,010 [memo.py] => Learning on 20-25
2025-01-11 02:42:21,011 [memo.py] => All params: 1877871
2025-01-11 02:42:21,012 [memo.py] => Trainable params: 471919
2025-01-11 02:54:16,534 [memo.py] => Task 4, Epoch 170/170 => Loss 0.004, Loss_clf 0.003, Loss_aux 0.001, Train_accy 100.00
2025-01-11 02:54:16,539 [base.py] => Reducing exemplars...(190 per classes)
2025-01-11 02:54:35,330 [base.py] => Constructing exemplars...(190 per classes)
2025-01-11 02:54:48,848 [memo.py] => Exemplar size: 4750
2025-01-11 02:54:48,848 [trainer.py] => CNN: {'total': np.float64(79.16), '00-09': np.float64(82.7), '10-19': np.float64(72.5), '20-29': np.float64(85.4), 'old': np.float64(77.6), 'new': np.float64(85.4)}
2025-01-11 02:54:48,848 [trainer.py] => NME: {'total': np.float64(78.6), '00-09': np.float64(84.1), '10-19': np.float64(71.6), '20-29': np.float64(81.6), 'old': np.float64(77.85), 'new': np.float64(81.6)}
2025-01-11 02:54:48,848 [trainer.py] => CNN top1 curve: [np.float64(95.4), np.float64(90.6), np.float64(84.07), np.float64(79.7), np.float64(79.16)]
2025-01-11 02:54:48,848 [trainer.py] => CNN top5 curve: [np.float64(100.0), np.float64(99.3), np.float64(98.0), np.float64(96.1), np.float64(95.24)]
2025-01-11 02:54:48,848 [trainer.py] => NME top1 curve: [np.float64(95.8), np.float64(90.5), np.float64(82.2), np.float64(78.7), np.float64(78.6)]
2025-01-11 02:54:48,848 [trainer.py] => NME top5 curve: [np.float64(100.0), np.float64(99.4), np.float64(97.8), np.float64(95.95), np.float64(95.24)]

2025-01-11 02:54:48,849 [trainer.py] => All params: 1877871
2025-01-11 02:54:48,849 [trainer.py] => Trainable params: 471919
2025-01-11 02:54:48,862 [memo.py] => Learning on 25-30
2025-01-11 02:54:48,863 [memo.py] => All params: 2232884
2025-01-11 02:54:48,863 [memo.py] => Trainable params: 475444
2025-01-11 03:07:25,173 [memo.py] => Task 5, Epoch 170/170 => Loss 0.005, Loss_clf 0.004, Loss_aux 0.001, Train_accy 99.99
2025-01-11 03:07:25,179 [base.py] => Reducing exemplars...(159 per classes)
2025-01-11 03:07:48,155 [base.py] => Constructing exemplars...(159 per classes)
2025-01-11 03:08:01,839 [memo.py] => Exemplar size: 4770
2025-01-11 03:08:01,839 [trainer.py] => CNN: {'total': np.float64(78.0), '00-09': np.float64(82.0), '10-19': np.float64(69.5), '20-29': np.float64(82.5), 'old': np.float64(77.4), 'new': np.float64(81.0)}
2025-01-11 03:08:01,839 [trainer.py] => NME: {'total': np.float64(76.27), '00-09': np.float64(83.1), '10-19': np.float64(68.3), '20-29': np.float64(77.4), 'old': np.float64(76.32), 'new': np.float64(76.0)}
2025-01-11 03:08:01,839 [trainer.py] => CNN top1 curve: [np.float64(95.4), np.float64(90.6), np.float64(84.07), np.float64(79.7), np.float64(79.16), np.float64(78.0)]
2025-01-11 03:08:01,839 [trainer.py] => CNN top5 curve: [np.float64(100.0), np.float64(99.3), np.float64(98.0), np.float64(96.1), np.float64(95.24), np.float64(94.47)]
2025-01-11 03:08:01,839 [trainer.py] => NME top1 curve: [np.float64(95.8), np.float64(90.5), np.float64(82.2), np.float64(78.7), np.float64(78.6), np.float64(76.27)]
2025-01-11 03:08:01,839 [trainer.py] => NME top5 curve: [np.float64(100.0), np.float64(99.4), np.float64(97.8), np.float64(95.95), np.float64(95.24), np.float64(94.53)]

2025-01-11 03:08:01,840 [trainer.py] => All params: 2232884
2025-01-11 03:08:01,840 [trainer.py] => Trainable params: 475444
2025-01-11 03:08:01,853 [memo.py] => Learning on 30-35
2025-01-11 03:08:01,854 [memo.py] => All params: 2588537
2025-01-11 03:08:01,854 [memo.py] => Trainable params: 479609
2025-01-11 03:20:57,684 [memo.py] => Task 6, Epoch 170/170 => Loss 0.005, Loss_clf 0.004, Loss_aux 0.001, Train_accy 99.97
2025-01-11 03:20:57,690 [base.py] => Reducing exemplars...(136 per classes)
2025-01-11 03:21:25,170 [base.py] => Constructing exemplars...(136 per classes)
2025-01-11 03:21:38,905 [memo.py] => Exemplar size: 4760
2025-01-11 03:21:38,905 [trainer.py] => CNN: {'total': np.float64(76.57), '00-09': np.float64(79.7), '10-19': np.float64(67.7), '20-29': np.float64(81.0), '30-39': np.float64(79.2), 'old': np.float64(76.13), 'new': np.float64(79.2)}
2025-01-11 03:21:38,905 [trainer.py] => NME: {'total': np.float64(74.29), '00-09': np.float64(80.1), '10-19': np.float64(67.1), '20-29': np.float64(75.8), '30-39': np.float64(74.0), 'old': np.float64(74.33), 'new': np.float64(74.0)}
2025-01-11 03:21:38,905 [trainer.py] => CNN top1 curve: [np.float64(95.4), np.float64(90.6), np.float64(84.07), np.float64(79.7), np.float64(79.16), np.float64(78.0), np.float64(76.57)]
2025-01-11 03:21:38,905 [trainer.py] => CNN top5 curve: [np.float64(100.0), np.float64(99.3), np.float64(98.0), np.float64(96.1), np.float64(95.24), np.float64(94.47), np.float64(93.71)]
2025-01-11 03:21:38,905 [trainer.py] => NME top1 curve: [np.float64(95.8), np.float64(90.5), np.float64(82.2), np.float64(78.7), np.float64(78.6), np.float64(76.27), np.float64(74.29)]
2025-01-11 03:21:38,905 [trainer.py] => NME top5 curve: [np.float64(100.0), np.float64(99.4), np.float64(97.8), np.float64(95.95), np.float64(95.24), np.float64(94.53), np.float64(93.74)]

2025-01-11 03:21:38,906 [trainer.py] => All params: 2588537
2025-01-11 03:21:38,907 [trainer.py] => Trainable params: 479609
2025-01-11 03:21:38,919 [memo.py] => Learning on 35-40
2025-01-11 03:21:38,920 [memo.py] => All params: 2944830
2025-01-11 03:21:38,921 [memo.py] => Trainable params: 484414
2025-01-11 03:35:00,448 [memo.py] => Task 7, Epoch 170/170 => Loss 0.006, Loss_clf 0.004, Loss_aux 0.002, Train_accy 99.99
2025-01-11 03:35:00,455 [base.py] => Reducing exemplars...(119 per classes)
2025-01-11 03:35:32,261 [base.py] => Constructing exemplars...(119 per classes)
2025-01-11 03:35:46,832 [memo.py] => Exemplar size: 4760
2025-01-11 03:35:46,832 [trainer.py] => CNN: {'total': np.float64(75.15), '00-09': np.float64(78.4), '10-19': np.float64(66.4), '20-29': np.float64(79.9), '30-39': np.float64(75.9), 'old': np.float64(75.31), 'new': np.float64(74.0)}
2025-01-11 03:35:46,832 [trainer.py] => NME: {'total': np.float64(73.08), '00-09': np.float64(78.4), '10-19': np.float64(67.4), '20-29': np.float64(75.8), '30-39': np.float64(70.7), 'old': np.float64(73.66), 'new': np.float64(69.0)}
2025-01-11 03:35:46,832 [trainer.py] => CNN top1 curve: [np.float64(95.4), np.float64(90.6), np.float64(84.07), np.float64(79.7), np.float64(79.16), np.float64(78.0), np.float64(76.57), np.float64(75.15)]
2025-01-11 03:35:46,832 [trainer.py] => CNN top5 curve: [np.float64(100.0), np.float64(99.3), np.float64(98.0), np.float64(96.1), np.float64(95.24), np.float64(94.47), np.float64(93.71), np.float64(93.25)]
2025-01-11 03:35:46,832 [trainer.py] => NME top1 curve: [np.float64(95.8), np.float64(90.5), np.float64(82.2), np.float64(78.7), np.float64(78.6), np.float64(76.27), np.float64(74.29), np.float64(73.08)]
2025-01-11 03:35:46,832 [trainer.py] => NME top5 curve: [np.float64(100.0), np.float64(99.4), np.float64(97.8), np.float64(95.95), np.float64(95.24), np.float64(94.53), np.float64(93.74), np.float64(93.18)]

2025-01-11 03:35:46,833 [trainer.py] => All params: 2944830
2025-01-11 03:35:46,834 [trainer.py] => Trainable params: 484414
2025-01-11 03:35:46,847 [memo.py] => Learning on 40-45
2025-01-11 03:35:46,848 [memo.py] => All params: 3301763
2025-01-11 03:35:46,848 [memo.py] => Trainable params: 489859
2025-01-11 03:49:32,591 [memo.py] => Task 8, Epoch 170/170 => Loss 0.005, Loss_clf 0.004, Loss_aux 0.001, Train_accy 100.00
2025-01-11 03:49:32,597 [base.py] => Reducing exemplars...(106 per classes)
2025-01-11 03:50:10,319 [base.py] => Constructing exemplars...(106 per classes)
2025-01-11 03:50:25,326 [memo.py] => Exemplar size: 4770
2025-01-11 03:50:25,326 [trainer.py] => CNN: {'total': np.float64(72.98), '00-09': np.float64(74.1), '10-19': np.float64(63.9), '20-29': np.float64(75.6), '30-39': np.float64(74.7), '40-49': np.float64(80.2), 'old': np.float64(72.08), 'new': np.float64(80.2)}
2025-01-11 03:50:25,326 [trainer.py] => NME: {'total': np.float64(71.69), '00-09': np.float64(76.0), '10-19': np.float64(65.4), '20-29': np.float64(74.1), '30-39': np.float64(69.7), '40-49': np.float64(74.8), 'old': np.float64(71.3), 'new': np.float64(74.8)}
2025-01-11 03:50:25,326 [trainer.py] => CNN top1 curve: [np.float64(95.4), np.float64(90.6), np.float64(84.07), np.float64(79.7), np.float64(79.16), np.float64(78.0), np.float64(76.57), np.float64(75.15), np.float64(72.98)]
2025-01-11 03:50:25,326 [trainer.py] => CNN top5 curve: [np.float64(100.0), np.float64(99.3), np.float64(98.0), np.float64(96.1), np.float64(95.24), np.float64(94.47), np.float64(93.71), np.float64(93.25), np.float64(92.13)]
2025-01-11 03:50:25,326 [trainer.py] => NME top1 curve: [np.float64(95.8), np.float64(90.5), np.float64(82.2), np.float64(78.7), np.float64(78.6), np.float64(76.27), np.float64(74.29), np.float64(73.08), np.float64(71.69)]
2025-01-11 03:50:25,326 [trainer.py] => NME top5 curve: [np.float64(100.0), np.float64(99.4), np.float64(97.8), np.float64(95.95), np.float64(95.24), np.float64(94.53), np.float64(93.74), np.float64(93.18), np.float64(92.56)]

2025-01-11 03:50:25,327 [trainer.py] => All params: 3301763
2025-01-11 03:50:25,328 [trainer.py] => Trainable params: 489859
2025-01-11 03:50:25,341 [memo.py] => Learning on 45-50
2025-01-11 03:50:25,342 [memo.py] => All params: 3659336
2025-01-11 03:50:25,343 [memo.py] => Trainable params: 495944
2025-01-11 04:04:43,599 [memo.py] => Task 9, Epoch 170/170 => Loss 0.006, Loss_clf 0.005, Loss_aux 0.001, Train_accy 99.99
2025-01-11 04:04:43,605 [base.py] => Reducing exemplars...(95 per classes)
2025-01-11 04:05:24,304 [base.py] => Constructing exemplars...(95 per classes)
2025-01-11 04:05:39,324 [memo.py] => Exemplar size: 4750
2025-01-11 04:05:39,324 [trainer.py] => CNN: {'total': np.float64(72.42), '00-09': np.float64(73.5), '10-19': np.float64(60.4), '20-29': np.float64(75.7), '30-39': np.float64(72.5), '40-49': np.float64(80.0), 'old': np.float64(71.8), 'new': np.float64(78.0)}
2025-01-11 04:05:39,324 [trainer.py] => NME: {'total': np.float64(70.94), '00-09': np.float64(76.7), '10-19': np.float64(63.5), '20-29': np.float64(73.0), '30-39': np.float64(66.3), '40-49': np.float64(75.2), 'old': np.float64(70.38), 'new': np.float64(76.0)}
2025-01-11 04:05:39,324 [trainer.py] => CNN top1 curve: [np.float64(95.4), np.float64(90.6), np.float64(84.07), np.float64(79.7), np.float64(79.16), np.float64(78.0), np.float64(76.57), np.float64(75.15), np.float64(72.98), np.float64(72.42)]
2025-01-11 04:05:39,325 [trainer.py] => CNN top5 curve: [np.float64(100.0), np.float64(99.3), np.float64(98.0), np.float64(96.1), np.float64(95.24), np.float64(94.47), np.float64(93.71), np.float64(93.25), np.float64(92.13), np.float64(92.04)]
2025-01-11 04:05:39,325 [trainer.py] => NME top1 curve: [np.float64(95.8), np.float64(90.5), np.float64(82.2), np.float64(78.7), np.float64(78.6), np.float64(76.27), np.float64(74.29), np.float64(73.08), np.float64(71.69), np.float64(70.94)]
2025-01-11 04:05:39,325 [trainer.py] => NME top5 curve: [np.float64(100.0), np.float64(99.4), np.float64(97.8), np.float64(95.95), np.float64(95.24), np.float64(94.53), np.float64(93.74), np.float64(93.18), np.float64(92.56), np.float64(92.18)]

2025-01-11 04:05:39,326 [trainer.py] => All params: 3659336
2025-01-11 04:05:39,326 [trainer.py] => Trainable params: 495944
2025-01-11 04:05:39,339 [memo.py] => Learning on 50-55
2025-01-11 04:05:39,340 [memo.py] => All params: 4017549
2025-01-11 04:05:39,341 [memo.py] => Trainable params: 502669
2025-01-11 04:20:21,493 [memo.py] => Task 10, Epoch 170/170 => Loss 0.005, Loss_clf 0.005, Loss_aux 0.001, Train_accy 99.99
2025-01-11 04:20:21,500 [base.py] => Reducing exemplars...(86 per classes)
2025-01-11 04:21:06,347 [base.py] => Constructing exemplars...(86 per classes)
2025-01-11 04:21:22,808 [memo.py] => Exemplar size: 4730
2025-01-11 04:21:22,809 [trainer.py] => CNN: {'total': np.float64(71.67), '00-09': np.float64(72.1), '10-19': np.float64(59.6), '20-29': np.float64(72.5), '30-39': np.float64(70.5), '40-49': np.float64(80.4), '50-59': np.float64(78.2), 'old': np.float64(71.02), 'new': np.float64(78.2)}
2025-01-11 04:21:22,809 [trainer.py] => NME: {'total': np.float64(70.45), '00-09': np.float64(73.8), '10-19': np.float64(63.7), '20-29': np.float64(73.1), '30-39': np.float64(66.2), '40-49': np.float64(73.2), '50-59': np.float64(75.0), 'old': np.float64(70.0), 'new': np.float64(75.0)}
2025-01-11 04:21:22,809 [trainer.py] => CNN top1 curve: [np.float64(95.4), np.float64(90.6), np.float64(84.07), np.float64(79.7), np.float64(79.16), np.float64(78.0), np.float64(76.57), np.float64(75.15), np.float64(72.98), np.float64(72.42), np.float64(71.67)]
2025-01-11 04:21:22,809 [trainer.py] => CNN top5 curve: [np.float64(100.0), np.float64(99.3), np.float64(98.0), np.float64(96.1), np.float64(95.24), np.float64(94.47), np.float64(93.71), np.float64(93.25), np.float64(92.13), np.float64(92.04), np.float64(91.4)]
2025-01-11 04:21:22,809 [trainer.py] => NME top1 curve: [np.float64(95.8), np.float64(90.5), np.float64(82.2), np.float64(78.7), np.float64(78.6), np.float64(76.27), np.float64(74.29), np.float64(73.08), np.float64(71.69), np.float64(70.94), np.float64(70.45)]
2025-01-11 04:21:22,809 [trainer.py] => NME top5 curve: [np.float64(100.0), np.float64(99.4), np.float64(97.8), np.float64(95.95), np.float64(95.24), np.float64(94.53), np.float64(93.74), np.float64(93.18), np.float64(92.56), np.float64(92.18), np.float64(91.71)]

2025-01-11 04:21:22,810 [trainer.py] => All params: 4017549
2025-01-11 04:21:22,811 [trainer.py] => Trainable params: 502669
2025-01-11 04:21:22,824 [memo.py] => Learning on 55-60
2025-01-11 04:21:22,825 [memo.py] => All params: 4376402
2025-01-11 04:21:22,826 [memo.py] => Trainable params: 510034
2025-01-11 04:36:24,068 [memo.py] => Task 11, Epoch 170/170 => Loss 0.006, Loss_clf 0.005, Loss_aux 0.001, Train_accy 100.00
2025-01-11 04:36:24,075 [base.py] => Reducing exemplars...(79 per classes)
2025-01-11 04:37:14,663 [base.py] => Constructing exemplars...(79 per classes)
2025-01-11 04:37:31,215 [memo.py] => Exemplar size: 4740
2025-01-11 04:37:31,216 [trainer.py] => CNN: {'total': np.float64(70.18), '00-09': np.float64(70.8), '10-19': np.float64(58.4), '20-29': np.float64(72.4), '30-39': np.float64(69.1), '40-49': np.float64(77.6), '50-59': np.float64(72.8), 'old': np.float64(70.55), 'new': np.float64(66.2)}
2025-01-11 04:37:31,216 [trainer.py] => NME: {'total': np.float64(69.08), '00-09': np.float64(73.0), '10-19': np.float64(60.6), '20-29': np.float64(72.7), '30-39': np.float64(65.6), '40-49': np.float64(73.4), '50-59': np.float64(69.2), 'old': np.float64(69.25), 'new': np.float64(67.2)}
2025-01-11 04:37:31,216 [trainer.py] => CNN top1 curve: [np.float64(95.4), np.float64(90.6), np.float64(84.07), np.float64(79.7), np.float64(79.16), np.float64(78.0), np.float64(76.57), np.float64(75.15), np.float64(72.98), np.float64(72.42), np.float64(71.67), np.float64(70.18)]
2025-01-11 04:37:31,216 [trainer.py] => CNN top5 curve: [np.float64(100.0), np.float64(99.3), np.float64(98.0), np.float64(96.1), np.float64(95.24), np.float64(94.47), np.float64(93.71), np.float64(93.25), np.float64(92.13), np.float64(92.04), np.float64(91.4), np.float64(90.62)]
2025-01-11 04:37:31,216 [trainer.py] => NME top1 curve: [np.float64(95.8), np.float64(90.5), np.float64(82.2), np.float64(78.7), np.float64(78.6), np.float64(76.27), np.float64(74.29), np.float64(73.08), np.float64(71.69), np.float64(70.94), np.float64(70.45), np.float64(69.08)]
2025-01-11 04:37:31,216 [trainer.py] => NME top5 curve: [np.float64(100.0), np.float64(99.4), np.float64(97.8), np.float64(95.95), np.float64(95.24), np.float64(94.53), np.float64(93.74), np.float64(93.18), np.float64(92.56), np.float64(92.18), np.float64(91.71), np.float64(90.97)]

2025-01-11 04:37:31,217 [trainer.py] => All params: 4376402
2025-01-11 04:37:31,218 [trainer.py] => Trainable params: 510034
2025-01-11 04:37:31,231 [memo.py] => Learning on 60-65
2025-01-11 04:37:31,232 [memo.py] => All params: 4735895
2025-01-11 04:37:31,233 [memo.py] => Trainable params: 518039
2025-01-11 04:53:05,631 [memo.py] => Task 12, Epoch 170/170 => Loss 0.006, Loss_clf 0.005, Loss_aux 0.001, Train_accy 99.99
2025-01-11 04:53:05,638 [base.py] => Reducing exemplars...(73 per classes)
2025-01-11 04:54:00,323 [base.py] => Constructing exemplars...(73 per classes)
2025-01-11 04:54:15,978 [memo.py] => Exemplar size: 4745
2025-01-11 04:54:15,979 [trainer.py] => CNN: {'total': np.float64(69.23), '00-09': np.float64(70.0), '10-19': np.float64(57.4), '20-29': np.float64(71.3), '30-39': np.float64(67.3), '40-49': np.float64(76.3), '50-59': np.float64(72.3), '60-69': np.float64(70.8), 'old': np.float64(69.1), 'new': np.float64(70.8)}
2025-01-11 04:54:15,979 [trainer.py] => NME: {'total': np.float64(67.71), '00-09': np.float64(72.3), '10-19': np.float64(61.3), '20-29': np.float64(71.9), '30-39': np.float64(64.0), '40-49': np.float64(71.5), '50-59': np.float64(64.5), '60-69': np.float64(69.2), 'old': np.float64(67.58), 'new': np.float64(69.2)}
2025-01-11 04:54:15,979 [trainer.py] => CNN top1 curve: [np.float64(95.4), np.float64(90.6), np.float64(84.07), np.float64(79.7), np.float64(79.16), np.float64(78.0), np.float64(76.57), np.float64(75.15), np.float64(72.98), np.float64(72.42), np.float64(71.67), np.float64(70.18), np.float64(69.23)]
2025-01-11 04:54:15,979 [trainer.py] => CNN top5 curve: [np.float64(100.0), np.float64(99.3), np.float64(98.0), np.float64(96.1), np.float64(95.24), np.float64(94.47), np.float64(93.71), np.float64(93.25), np.float64(92.13), np.float64(92.04), np.float64(91.4), np.float64(90.62), np.float64(90.42)]
2025-01-11 04:54:15,979 [trainer.py] => NME top1 curve: [np.float64(95.8), np.float64(90.5), np.float64(82.2), np.float64(78.7), np.float64(78.6), np.float64(76.27), np.float64(74.29), np.float64(73.08), np.float64(71.69), np.float64(70.94), np.float64(70.45), np.float64(69.08), np.float64(67.71)]
2025-01-11 04:54:15,979 [trainer.py] => NME top5 curve: [np.float64(100.0), np.float64(99.4), np.float64(97.8), np.float64(95.95), np.float64(95.24), np.float64(94.53), np.float64(93.74), np.float64(93.18), np.float64(92.56), np.float64(92.18), np.float64(91.71), np.float64(90.97), np.float64(90.05)]

2025-01-11 04:54:15,980 [trainer.py] => All params: 4735895
2025-01-11 04:54:15,981 [trainer.py] => Trainable params: 518039
2025-01-11 04:54:15,994 [memo.py] => Learning on 65-70
2025-01-11 04:54:15,995 [memo.py] => All params: 5096028
2025-01-11 04:54:15,996 [memo.py] => Trainable params: 526684
2025-01-11 05:10:17,713 [memo.py] => Task 13, Epoch 170/170 => Loss 0.006, Loss_clf 0.005, Loss_aux 0.001, Train_accy 99.97
2025-01-11 05:10:17,719 [base.py] => Reducing exemplars...(68 per classes)
2025-01-11 05:11:19,391 [base.py] => Constructing exemplars...(68 per classes)
2025-01-11 05:11:37,199 [memo.py] => Exemplar size: 4760
2025-01-11 05:11:37,199 [trainer.py] => CNN: {'total': np.float64(69.09), '00-09': np.float64(69.4), '10-19': np.float64(55.5), '20-29': np.float64(71.3), '30-39': np.float64(65.6), '40-49': np.float64(74.6), '50-59': np.float64(69.0), '60-69': np.float64(78.2), 'old': np.float64(68.18), 'new': np.float64(80.8)}
2025-01-11 05:11:37,199 [trainer.py] => NME: {'total': np.float64(67.9), '00-09': np.float64(72.6), '10-19': np.float64(60.4), '20-29': np.float64(71.7), '30-39': np.float64(63.0), '40-49': np.float64(71.1), '50-59': np.float64(63.1), '60-69': np.float64(73.4), 'old': np.float64(67.03), 'new': np.float64(79.2)}
2025-01-11 05:11:37,199 [trainer.py] => CNN top1 curve: [np.float64(95.4), np.float64(90.6), np.float64(84.07), np.float64(79.7), np.float64(79.16), np.float64(78.0), np.float64(76.57), np.float64(75.15), np.float64(72.98), np.float64(72.42), np.float64(71.67), np.float64(70.18), np.float64(69.23), np.float64(69.09)]
2025-01-11 05:11:37,199 [trainer.py] => CNN top5 curve: [np.float64(100.0), np.float64(99.3), np.float64(98.0), np.float64(96.1), np.float64(95.24), np.float64(94.47), np.float64(93.71), np.float64(93.25), np.float64(92.13), np.float64(92.04), np.float64(91.4), np.float64(90.62), np.float64(90.42), np.float64(89.94)]
2025-01-11 05:11:37,199 [trainer.py] => NME top1 curve: [np.float64(95.8), np.float64(90.5), np.float64(82.2), np.float64(78.7), np.float64(78.6), np.float64(76.27), np.float64(74.29), np.float64(73.08), np.float64(71.69), np.float64(70.94), np.float64(70.45), np.float64(69.08), np.float64(67.71), np.float64(67.9)]
2025-01-11 05:11:37,199 [trainer.py] => NME top5 curve: [np.float64(100.0), np.float64(99.4), np.float64(97.8), np.float64(95.95), np.float64(95.24), np.float64(94.53), np.float64(93.74), np.float64(93.18), np.float64(92.56), np.float64(92.18), np.float64(91.71), np.float64(90.97), np.float64(90.05), np.float64(90.0)]

2025-01-11 05:11:37,200 [trainer.py] => All params: 5096028
2025-01-11 05:11:37,201 [trainer.py] => Trainable params: 526684
2025-01-11 05:11:37,214 [memo.py] => Learning on 70-75
2025-01-11 05:11:37,216 [memo.py] => All params: 5456801
2025-01-11 05:11:37,217 [memo.py] => Trainable params: 535969
2025-01-11 05:28:00,374 [memo.py] => Task 14, Epoch 170/170 => Loss 0.006, Loss_clf 0.005, Loss_aux 0.001, Train_accy 100.00
2025-01-11 05:28:00,380 [base.py] => Reducing exemplars...(63 per classes)
2025-01-11 05:29:08,523 [base.py] => Constructing exemplars...(63 per classes)
2025-01-11 05:29:25,418 [memo.py] => Exemplar size: 4725
2025-01-11 05:29:25,418 [trainer.py] => CNN: {'total': np.float64(67.75), '00-09': np.float64(67.6), '10-19': np.float64(55.4), '20-29': np.float64(70.6), '30-39': np.float64(62.6), '40-49': np.float64(73.9), '50-59': np.float64(65.4), '60-69': np.float64(78.6), '70-79': np.float64(68.0), 'old': np.float64(67.73), 'new': np.float64(68.0)}
2025-01-11 05:29:25,418 [trainer.py] => NME: {'total': np.float64(66.16), '00-09': np.float64(70.8), '10-19': np.float64(59.7), '20-29': np.float64(70.6), '30-39': np.float64(60.2), '40-49': np.float64(70.6), '50-59': np.float64(60.6), '60-69': np.float64(68.8), '70-79': np.float64(69.8), 'old': np.float64(65.9), 'new': np.float64(69.8)}
2025-01-11 05:29:25,418 [trainer.py] => CNN top1 curve: [np.float64(95.4), np.float64(90.6), np.float64(84.07), np.float64(79.7), np.float64(79.16), np.float64(78.0), np.float64(76.57), np.float64(75.15), np.float64(72.98), np.float64(72.42), np.float64(71.67), np.float64(70.18), np.float64(69.23), np.float64(69.09), np.float64(67.75)]
2025-01-11 05:29:25,418 [trainer.py] => CNN top5 curve: [np.float64(100.0), np.float64(99.3), np.float64(98.0), np.float64(96.1), np.float64(95.24), np.float64(94.47), np.float64(93.71), np.float64(93.25), np.float64(92.13), np.float64(92.04), np.float64(91.4), np.float64(90.62), np.float64(90.42), np.float64(89.94), np.float64(88.97)]
2025-01-11 05:29:25,418 [trainer.py] => NME top1 curve: [np.float64(95.8), np.float64(90.5), np.float64(82.2), np.float64(78.7), np.float64(78.6), np.float64(76.27), np.float64(74.29), np.float64(73.08), np.float64(71.69), np.float64(70.94), np.float64(70.45), np.float64(69.08), np.float64(67.71), np.float64(67.9), np.float64(66.16)]
2025-01-11 05:29:25,418 [trainer.py] => NME top5 curve: [np.float64(100.0), np.float64(99.4), np.float64(97.8), np.float64(95.95), np.float64(95.24), np.float64(94.53), np.float64(93.74), np.float64(93.18), np.float64(92.56), np.float64(92.18), np.float64(91.71), np.float64(90.97), np.float64(90.05), np.float64(90.0), np.float64(89.4)]

2025-01-11 05:29:25,419 [trainer.py] => All params: 5456801
2025-01-11 05:29:25,420 [trainer.py] => Trainable params: 535969
2025-01-11 05:29:25,434 [memo.py] => Learning on 75-80
2025-01-11 05:29:25,435 [memo.py] => All params: 5818214
2025-01-11 05:29:25,436 [memo.py] => Trainable params: 545894
2025-01-11 05:46:17,877 [memo.py] => Task 15, Epoch 170/170 => Loss 0.007, Loss_clf 0.005, Loss_aux 0.001, Train_accy 99.99
2025-01-11 05:46:17,884 [base.py] => Reducing exemplars...(59 per classes)
2025-01-11 05:47:29,625 [base.py] => Constructing exemplars...(59 per classes)
2025-01-11 05:47:46,675 [memo.py] => Exemplar size: 4720
2025-01-11 05:47:46,675 [trainer.py] => CNN: {'total': np.float64(66.12), '00-09': np.float64(67.7), '10-19': np.float64(53.6), '20-29': np.float64(69.6), '30-39': np.float64(60.7), '40-49': np.float64(71.9), '50-59': np.float64(62.3), '60-69': np.float64(76.0), '70-79': np.float64(67.2), 'old': np.float64(66.41), 'new': np.float64(61.8)}
2025-01-11 05:47:46,675 [trainer.py] => NME: {'total': np.float64(64.53), '00-09': np.float64(70.3), '10-19': np.float64(58.9), '20-29': np.float64(71.1), '30-39': np.float64(59.9), '40-49': np.float64(67.5), '50-59': np.float64(56.1), '60-69': np.float64(67.9), '70-79': np.float64(64.5), 'old': np.float64(64.47), 'new': np.float64(65.4)}
2025-01-11 05:47:46,675 [trainer.py] => CNN top1 curve: [np.float64(95.4), np.float64(90.6), np.float64(84.07), np.float64(79.7), np.float64(79.16), np.float64(78.0), np.float64(76.57), np.float64(75.15), np.float64(72.98), np.float64(72.42), np.float64(71.67), np.float64(70.18), np.float64(69.23), np.float64(69.09), np.float64(67.75), np.float64(66.12)]
2025-01-11 05:47:46,675 [trainer.py] => CNN top5 curve: [np.float64(100.0), np.float64(99.3), np.float64(98.0), np.float64(96.1), np.float64(95.24), np.float64(94.47), np.float64(93.71), np.float64(93.25), np.float64(92.13), np.float64(92.04), np.float64(91.4), np.float64(90.62), np.float64(90.42), np.float64(89.94), np.float64(88.97), np.float64(88.54)]
2025-01-11 05:47:46,675 [trainer.py] => NME top1 curve: [np.float64(95.8), np.float64(90.5), np.float64(82.2), np.float64(78.7), np.float64(78.6), np.float64(76.27), np.float64(74.29), np.float64(73.08), np.float64(71.69), np.float64(70.94), np.float64(70.45), np.float64(69.08), np.float64(67.71), np.float64(67.9), np.float64(66.16), np.float64(64.53)]
2025-01-11 05:47:46,675 [trainer.py] => NME top5 curve: [np.float64(100.0), np.float64(99.4), np.float64(97.8), np.float64(95.95), np.float64(95.24), np.float64(94.53), np.float64(93.74), np.float64(93.18), np.float64(92.56), np.float64(92.18), np.float64(91.71), np.float64(90.97), np.float64(90.05), np.float64(90.0), np.float64(89.4), np.float64(88.78)]

2025-01-11 05:47:46,677 [trainer.py] => All params: 5818214
2025-01-11 05:47:46,678 [trainer.py] => Trainable params: 545894
2025-01-11 05:47:46,691 [memo.py] => Learning on 80-85
2025-01-11 05:47:46,693 [memo.py] => All params: 6180267
2025-01-11 05:47:46,694 [memo.py] => Trainable params: 556459
2025-01-11 06:05:09,848 [memo.py] => Task 16, Epoch 170/170 => Loss 0.006, Loss_clf 0.005, Loss_aux 0.001, Train_accy 100.00
2025-01-11 06:05:09,854 [base.py] => Reducing exemplars...(56 per classes)
2025-01-11 06:06:24,184 [base.py] => Constructing exemplars...(56 per classes)
2025-01-11 06:06:41,866 [memo.py] => Exemplar size: 4760
2025-01-11 06:06:41,866 [trainer.py] => CNN: {'total': np.float64(65.05), '00-09': np.float64(64.8), '10-19': np.float64(52.6), '20-29': np.float64(67.0), '30-39': np.float64(59.3), '40-49': np.float64(68.7), '50-59': np.float64(58.8), '60-69': np.float64(73.7), '70-79': np.float64(72.7), '80-89': np.float64(70.6), 'old': np.float64(64.7), 'new': np.float64(70.6)}
2025-01-11 06:06:41,866 [trainer.py] => NME: {'total': np.float64(63.76), '00-09': np.float64(68.4), '10-19': np.float64(55.8), '20-29': np.float64(69.2), '30-39': np.float64(59.9), '40-49': np.float64(67.4), '50-59': np.float64(56.4), '60-69': np.float64(66.6), '70-79': np.float64(63.5), '80-89': np.float64(69.6), 'old': np.float64(63.4), 'new': np.float64(69.6)}
2025-01-11 06:06:41,866 [trainer.py] => CNN top1 curve: [np.float64(95.4), np.float64(90.6), np.float64(84.07), np.float64(79.7), np.float64(79.16), np.float64(78.0), np.float64(76.57), np.float64(75.15), np.float64(72.98), np.float64(72.42), np.float64(71.67), np.float64(70.18), np.float64(69.23), np.float64(69.09), np.float64(67.75), np.float64(66.12), np.float64(65.05)]
2025-01-11 06:06:41,866 [trainer.py] => CNN top5 curve: [np.float64(100.0), np.float64(99.3), np.float64(98.0), np.float64(96.1), np.float64(95.24), np.float64(94.47), np.float64(93.71), np.float64(93.25), np.float64(92.13), np.float64(92.04), np.float64(91.4), np.float64(90.62), np.float64(90.42), np.float64(89.94), np.float64(88.97), np.float64(88.54), np.float64(88.32)]
2025-01-11 06:06:41,866 [trainer.py] => NME top1 curve: [np.float64(95.8), np.float64(90.5), np.float64(82.2), np.float64(78.7), np.float64(78.6), np.float64(76.27), np.float64(74.29), np.float64(73.08), np.float64(71.69), np.float64(70.94), np.float64(70.45), np.float64(69.08), np.float64(67.71), np.float64(67.9), np.float64(66.16), np.float64(64.53), np.float64(63.76)]
2025-01-11 06:06:41,866 [trainer.py] => NME top5 curve: [np.float64(100.0), np.float64(99.4), np.float64(97.8), np.float64(95.95), np.float64(95.24), np.float64(94.53), np.float64(93.74), np.float64(93.18), np.float64(92.56), np.float64(92.18), np.float64(91.71), np.float64(90.97), np.float64(90.05), np.float64(90.0), np.float64(89.4), np.float64(88.78), np.float64(88.47)]

2025-01-11 06:06:41,868 [trainer.py] => All params: 6180267
2025-01-11 06:06:41,869 [trainer.py] => Trainable params: 556459
2025-01-11 06:06:41,882 [memo.py] => Learning on 85-90
2025-01-11 06:06:41,884 [memo.py] => All params: 6542960
2025-01-11 06:06:41,885 [memo.py] => Trainable params: 567664
2025-01-11 06:24:28,789 [memo.py] => Task 17, Epoch 170/170 => Loss 0.008, Loss_clf 0.006, Loss_aux 0.001, Train_accy 100.00
2025-01-11 06:24:28,795 [base.py] => Reducing exemplars...(53 per classes)
2025-01-11 06:25:48,162 [base.py] => Constructing exemplars...(53 per classes)
2025-01-11 06:26:07,476 [memo.py] => Exemplar size: 4770
2025-01-11 06:26:07,476 [trainer.py] => CNN: {'total': np.float64(63.96), '00-09': np.float64(64.4), '10-19': np.float64(51.1), '20-29': np.float64(65.9), '30-39': np.float64(58.4), '40-49': np.float64(66.2), '50-59': np.float64(59.2), '60-69': np.float64(70.2), '70-79': np.float64(69.8), '80-89': np.float64(70.4), 'old': np.float64(64.01), 'new': np.float64(63.0)}
2025-01-11 06:26:07,476 [trainer.py] => NME: {'total': np.float64(62.72), '00-09': np.float64(66.9), '10-19': np.float64(56.6), '20-29': np.float64(69.3), '30-39': np.float64(58.7), '40-49': np.float64(65.8), '50-59': np.float64(56.0), '60-69': np.float64(65.1), '70-79': np.float64(62.1), '80-89': np.float64(64.0), 'old': np.float64(62.87), 'new': np.float64(60.2)}
2025-01-11 06:26:07,476 [trainer.py] => CNN top1 curve: [np.float64(95.4), np.float64(90.6), np.float64(84.07), np.float64(79.7), np.float64(79.16), np.float64(78.0), np.float64(76.57), np.float64(75.15), np.float64(72.98), np.float64(72.42), np.float64(71.67), np.float64(70.18), np.float64(69.23), np.float64(69.09), np.float64(67.75), np.float64(66.12), np.float64(65.05), np.float64(63.96)]
2025-01-11 06:26:07,476 [trainer.py] => CNN top5 curve: [np.float64(100.0), np.float64(99.3), np.float64(98.0), np.float64(96.1), np.float64(95.24), np.float64(94.47), np.float64(93.71), np.float64(93.25), np.float64(92.13), np.float64(92.04), np.float64(91.4), np.float64(90.62), np.float64(90.42), np.float64(89.94), np.float64(88.97), np.float64(88.54), np.float64(88.32), np.float64(87.84)]
2025-01-11 06:26:07,476 [trainer.py] => NME top1 curve: [np.float64(95.8), np.float64(90.5), np.float64(82.2), np.float64(78.7), np.float64(78.6), np.float64(76.27), np.float64(74.29), np.float64(73.08), np.float64(71.69), np.float64(70.94), np.float64(70.45), np.float64(69.08), np.float64(67.71), np.float64(67.9), np.float64(66.16), np.float64(64.53), np.float64(63.76), np.float64(62.72)]
2025-01-11 06:26:07,476 [trainer.py] => NME top5 curve: [np.float64(100.0), np.float64(99.4), np.float64(97.8), np.float64(95.95), np.float64(95.24), np.float64(94.53), np.float64(93.74), np.float64(93.18), np.float64(92.56), np.float64(92.18), np.float64(91.71), np.float64(90.97), np.float64(90.05), np.float64(90.0), np.float64(89.4), np.float64(88.78), np.float64(88.47), np.float64(87.77)]

2025-01-11 06:26:07,478 [trainer.py] => All params: 6542960
2025-01-11 06:26:07,479 [trainer.py] => Trainable params: 567664
2025-01-11 06:26:07,492 [memo.py] => Learning on 90-95
2025-01-11 06:26:07,494 [memo.py] => All params: 6906293
2025-01-11 06:26:07,495 [memo.py] => Trainable params: 579509
2025-01-11 06:44:16,374 [memo.py] => Task 18, Epoch 170/170 => Loss 0.008, Loss_clf 0.007, Loss_aux 0.001, Train_accy 99.99
2025-01-11 06:44:16,381 [base.py] => Reducing exemplars...(50 per classes)
2025-01-11 06:45:40,414 [base.py] => Constructing exemplars...(50 per classes)
2025-01-11 06:45:59,569 [memo.py] => Exemplar size: 4750
2025-01-11 06:45:59,569 [trainer.py] => CNN: {'total': np.float64(63.13), '00-09': np.float64(62.4), '10-19': np.float64(50.0), '20-29': np.float64(66.4), '30-39': np.float64(59.5), '40-49': np.float64(64.0), '50-59': np.float64(57.0), '60-69': np.float64(69.7), '70-79': np.float64(63.0), '80-89': np.float64(74.8), '90-99': np.float64(65.8), 'old': np.float64(62.98), 'new': np.float64(65.8)}
2025-01-11 06:45:59,569 [trainer.py] => NME: {'total': np.float64(61.33), '00-09': np.float64(66.0), '10-19': np.float64(54.9), '20-29': np.float64(68.1), '30-39': np.float64(58.9), '40-49': np.float64(64.2), '50-59': np.float64(54.4), '60-69': np.float64(64.8), '70-79': np.float64(58.9), '80-89': np.float64(61.3), '90-99': np.float64(62.2), 'old': np.float64(61.28), 'new': np.float64(62.2)}
2025-01-11 06:45:59,570 [trainer.py] => CNN top1 curve: [np.float64(95.4), np.float64(90.6), np.float64(84.07), np.float64(79.7), np.float64(79.16), np.float64(78.0), np.float64(76.57), np.float64(75.15), np.float64(72.98), np.float64(72.42), np.float64(71.67), np.float64(70.18), np.float64(69.23), np.float64(69.09), np.float64(67.75), np.float64(66.12), np.float64(65.05), np.float64(63.96), np.float64(63.13)]
2025-01-11 06:45:59,570 [trainer.py] => CNN top5 curve: [np.float64(100.0), np.float64(99.3), np.float64(98.0), np.float64(96.1), np.float64(95.24), np.float64(94.47), np.float64(93.71), np.float64(93.25), np.float64(92.13), np.float64(92.04), np.float64(91.4), np.float64(90.62), np.float64(90.42), np.float64(89.94), np.float64(88.97), np.float64(88.54), np.float64(88.32), np.float64(87.84), np.float64(86.77)]
2025-01-11 06:45:59,570 [trainer.py] => NME top1 curve: [np.float64(95.8), np.float64(90.5), np.float64(82.2), np.float64(78.7), np.float64(78.6), np.float64(76.27), np.float64(74.29), np.float64(73.08), np.float64(71.69), np.float64(70.94), np.float64(70.45), np.float64(69.08), np.float64(67.71), np.float64(67.9), np.float64(66.16), np.float64(64.53), np.float64(63.76), np.float64(62.72), np.float64(61.33)]
2025-01-11 06:45:59,570 [trainer.py] => NME top5 curve: [np.float64(100.0), np.float64(99.4), np.float64(97.8), np.float64(95.95), np.float64(95.24), np.float64(94.53), np.float64(93.74), np.float64(93.18), np.float64(92.56), np.float64(92.18), np.float64(91.71), np.float64(90.97), np.float64(90.05), np.float64(90.0), np.float64(89.4), np.float64(88.78), np.float64(88.47), np.float64(87.77), np.float64(86.93)]

2025-01-11 06:45:59,571 [trainer.py] => All params: 6906293
2025-01-11 06:45:59,572 [trainer.py] => Trainable params: 579509
2025-01-11 06:45:59,586 [memo.py] => Learning on 95-100
2025-01-11 06:45:59,588 [memo.py] => All params: 7270266
2025-01-11 06:45:59,589 [memo.py] => Trainable params: 591994
2025-01-11 07:04:43,198 [memo.py] => Task 19, Epoch 170/170 => Loss 0.008, Loss_clf 0.006, Loss_aux 0.001, Train_accy 99.99
2025-01-11 07:04:43,205 [base.py] => Reducing exemplars...(47 per classes)
2025-01-11 07:06:11,638 [base.py] => Constructing exemplars...(47 per classes)
2025-01-11 07:06:31,565 [memo.py] => Exemplar size: 4700
2025-01-11 07:06:31,565 [trainer.py] => CNN: {'total': np.float64(62.77), '00-09': np.float64(60.7), '10-19': np.float64(49.9), '20-29': np.float64(63.9), '30-39': np.float64(58.0), '40-49': np.float64(63.7), '50-59': np.float64(56.2), '60-69': np.float64(69.3), '70-79': np.float64(63.8), '80-89': np.float64(72.8), '90-99': np.float64(69.4), 'old': np.float64(62.78), 'new': np.float64(62.6)}
2025-01-11 07:06:31,565 [trainer.py] => NME: {'total': np.float64(60.49), '00-09': np.float64(65.2), '10-19': np.float64(55.0), '20-29': np.float64(67.9), '30-39': np.float64(57.7), '40-49': np.float64(63.2), '50-59': np.float64(54.4), '60-69': np.float64(64.3), '70-79': np.float64(57.4), '80-89': np.float64(60.3), '90-99': np.float64(59.5), 'old': np.float64(60.49), 'new': np.float64(60.4)}
2025-01-11 07:06:31,565 [trainer.py] => CNN top1 curve: [np.float64(95.4), np.float64(90.6), np.float64(84.07), np.float64(79.7), np.float64(79.16), np.float64(78.0), np.float64(76.57), np.float64(75.15), np.float64(72.98), np.float64(72.42), np.float64(71.67), np.float64(70.18), np.float64(69.23), np.float64(69.09), np.float64(67.75), np.float64(66.12), np.float64(65.05), np.float64(63.96), np.float64(63.13), np.float64(62.77)]
2025-01-11 07:06:31,565 [trainer.py] => CNN top5 curve: [np.float64(100.0), np.float64(99.3), np.float64(98.0), np.float64(96.1), np.float64(95.24), np.float64(94.47), np.float64(93.71), np.float64(93.25), np.float64(92.13), np.float64(92.04), np.float64(91.4), np.float64(90.62), np.float64(90.42), np.float64(89.94), np.float64(88.97), np.float64(88.54), np.float64(88.32), np.float64(87.84), np.float64(86.77), np.float64(86.41)]
2025-01-11 07:06:31,566 [trainer.py] => NME top1 curve: [np.float64(95.8), np.float64(90.5), np.float64(82.2), np.float64(78.7), np.float64(78.6), np.float64(76.27), np.float64(74.29), np.float64(73.08), np.float64(71.69), np.float64(70.94), np.float64(70.45), np.float64(69.08), np.float64(67.71), np.float64(67.9), np.float64(66.16), np.float64(64.53), np.float64(63.76), np.float64(62.72), np.float64(61.33), np.float64(60.49)]
2025-01-11 07:06:31,566 [trainer.py] => NME top5 curve: [np.float64(100.0), np.float64(99.4), np.float64(97.8), np.float64(95.95), np.float64(95.24), np.float64(94.53), np.float64(93.74), np.float64(93.18), np.float64(92.56), np.float64(92.18), np.float64(91.71), np.float64(90.97), np.float64(90.05), np.float64(90.0), np.float64(89.4), np.float64(88.78), np.float64(88.47), np.float64(87.77), np.float64(86.93), np.float64(86.04)]

2025-01-11 07:06:31,566 [trainer.py] => End Time:1736575591.5661645
